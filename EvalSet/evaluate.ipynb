{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "For the purposes of creating some form of annotation set, load in manually annotated sentence set (created from indications_and_usage section) and figure out a way to evaluate them using Huggingface methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Text/Annotations to JSON\n",
    "Datasets objects do not support individual item assignment, so all fields need to be prepopulated before loading in. Easiest way I could figure was to convert everything to a JSON object and load it in using load_datasets()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"1 INDICATIONS AND USAGE Memantine hydrochloride is an N-methyl-D-aspartate (NMDA) receptor antagonist indicated for the treatment of moderate to severe dementia of the Alzheimer's type. ( 1 ) Memantine hydrochloride tablets, USP are indicated for the treatment of moderate to severe dementia of the Alzheimer's type.\"],\n",
       " ['1 INDICATIONS AND USAGE Zenchent Fe, norethindrone and ethinyl estradiol tablets, chewable and ferrous fumarate tablets are indicated for use by females of reproductive potential to prevent pregnancy. â€¢ Zenchent Fe, norethindrone and ethinyl estradiol tablets, chewable and ferrous fumarate tablets is a progestin/estrogen COC indicated for use by females of reproductive potential to prevent pregnancy. ( 1 )'],\n",
       " ['1 INDICATIONS AND USAGE Alprazolam extended-release tablets are indicated for the treatment of panic disorder with or without agoraphobia, in adults. Alprazolam extended-release tablets are a benzodiazepine indicated for the treatment of panic disorder with or without agoraphobia, in adults. ( 1 )']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listify TEXT\n",
    "text_for_json = []\n",
    "for number in range(0,100):\n",
    "    with open(f'sentences/texts/{number}.txt','r') as f:\n",
    "        text_for_json.append(f.readlines())\n",
    "\n",
    "text_for_json[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [{'entity': 'CHEMICAL', 'start': '24', 'end': '35', 'word': 'Zenchent Fe'},\n",
       "  {'entity': 'CHEMICAL', 'start': '37', 'end': '50', 'word': 'norethindrone'},\n",
       "  {'entity': 'CHEMICAL',\n",
       "   'start': '55',\n",
       "   'end': '72',\n",
       "   'word': 'ethinyl estradiol'},\n",
       "  {'entity': 'CHEMICAL',\n",
       "   'start': '95',\n",
       "   'end': '111',\n",
       "   'word': 'ferrous fumarate'},\n",
       "  {'entity': 'CHEMICAL', 'start': '203', 'end': '214', 'word': 'Zenchent Fe'},\n",
       "  {'entity': 'CHEMICAL',\n",
       "   'start': '216',\n",
       "   'end': '229',\n",
       "   'word': 'norethindrone'},\n",
       "  {'entity': 'CHEMICAL',\n",
       "   'start': '234',\n",
       "   'end': '251',\n",
       "   'word': 'ethinyl estradiol'},\n",
       "  {'entity': 'CHEMICAL',\n",
       "   'start': '274',\n",
       "   'end': '290',\n",
       "   'word': 'ferrous fumarate'},\n",
       "  {'entity': 'CHEMICAL', 'start': '304', 'end': '313', 'word': 'progestin'},\n",
       "  {'entity': 'CHEMICAL', 'start': '314', 'end': '322', 'word': 'estrogen'}],\n",
       " [{'entity': 'CHEMICAL', 'start': '24', 'end': '34', 'word': 'Alprazolam'},\n",
       "  {'entity': 'CHEMICAL', 'start': '150', 'end': '160', 'word': 'Alprazolam'},\n",
       "  {'entity': 'CHEMICAL',\n",
       "   'start': '192',\n",
       "   'end': '206',\n",
       "   'word': 'benzodiazepine'}]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listify ANNOTATIONS\n",
    "ann_for_json = []\n",
    "for number in range(0,100):\n",
    "    with open(f'sentences/ann/{number}.ann','r') as f:\n",
    "        g = f.readlines()\n",
    "        entry = []\n",
    "        for item in g:\n",
    "            entry_dict = {}\n",
    "            entity_block = item.split('\\t')[1]\n",
    "            entry_dict['entity'] = entity_block.split(' ')[0]\n",
    "            entry_dict['start'] = entity_block.split(' ')[1]\n",
    "            entry_dict['end'] = entity_block.split(' ')[2]\n",
    "            entry_dict['word'] = item.split('\\t')[2].replace('\\n','')\n",
    "            entry.append(entry_dict)\n",
    "    ann_for_json.append(entry)\n",
    "ann_for_json[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to JSON and save\n",
    "import json\n",
    "data = json.dumps([{'text': text, 'human': ann} for text, ann in zip(text_for_json, ann_for_json)])\n",
    "with open('sentences/evalset.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset into Huggingface\n",
    "Use the load_dataset method to load in data in a JSON format. This will recognize the pre-built features 'text' and 'chemical_eval' built above using json.dumps from giant lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /Users/mjc014/.cache/huggingface/datasets/json/default-f01ef2a338e2bd42/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88db198a0d684981af93018a3c36df9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77305cd8ac7f412388019c615070d1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1bfbaf5d09429894bf8e43e89fb65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/mjc014/.cache/huggingface/datasets/json/default-f01ef2a338e2bd42/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\",data_files=\"sentences/evalset.json\",split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'human'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': '35', 'entity': 'CHEMICAL', 'start': '24', 'word': 'Zenchent Fe'},\n",
       " {'end': '50', 'entity': 'CHEMICAL', 'start': '37', 'word': 'norethindrone'},\n",
       " {'end': '72',\n",
       "  'entity': 'CHEMICAL',\n",
       "  'start': '55',\n",
       "  'word': 'ethinyl estradiol'},\n",
       " {'end': '111',\n",
       "  'entity': 'CHEMICAL',\n",
       "  'start': '95',\n",
       "  'word': 'ferrous fumarate'},\n",
       " {'end': '214', 'entity': 'CHEMICAL', 'start': '203', 'word': 'Zenchent Fe'},\n",
       " {'end': '229', 'entity': 'CHEMICAL', 'start': '216', 'word': 'norethindrone'},\n",
       " {'end': '251',\n",
       "  'entity': 'CHEMICAL',\n",
       "  'start': '234',\n",
       "  'word': 'ethinyl estradiol'},\n",
       " {'end': '290',\n",
       "  'entity': 'CHEMICAL',\n",
       "  'start': '274',\n",
       "  'word': 'ferrous fumarate'},\n",
       " {'end': '313', 'entity': 'CHEMICAL', 'start': '304', 'word': 'progestin'},\n",
       " {'end': '322', 'entity': 'CHEMICAL', 'start': '314', 'word': 'estrogen'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['human'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe\n",
    "Run pipe from Huggingface code and use map to have entities as their own field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "pipe_chemical = pipeline(\"token-classification\", model=\"alvaroalon2/biobert_chemical_ner\",aggregation_strategy=\"first\")\n",
    "\n",
    "def pipe(label_header,dataset):\n",
    "    def generate_chemical_ner(entry):\n",
    "        return {'bert': pipe_chemical(entry[label_header]) }\n",
    "    dataset = dataset.map(generate_chemical_ner)\n",
    "\n",
    "    return(dataset)\n",
    "\n",
    "def post_process(feature,dataset):\n",
    "    # Build DF\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for entry in dataset[feature]:\n",
    "        tdf = pd.DataFrame(entry)\n",
    "        df = pd.concat([df,tdf]).reset_index(drop=True)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d3bd9c315f49f58024245d95e12ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pipe('text', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'human', 'bert'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate \n",
    "Load in pipes, and create a piped dataset, figure out a comparison between the two? Calculate F1 score??  \n",
    "  \n",
    "*TODO: Clean this up from scratch, improve calculations, improve score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results of human labels / model predictions to DataFrame\n",
    "\n",
    "def post_process(feature,dataset):\n",
    "    # Build DF\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for entry in dataset[feature]:\n",
    "        tdf = pd.DataFrame(entry)\n",
    "        df = pd.concat([df,tdf]).reset_index(drop=True)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "def post_process2(feature,dataset):\n",
    "    # Build DF\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for entry in dataset[feature]:\n",
    "        tdf = pd.DataFrame(entry[0])\n",
    "        df = pd.concat([df,tdf]).reset_index(drop=True)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "evaluated = post_process('human',dataset) # human labels\n",
    "evaluated2 = post_process2('bert',dataset) # model predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all entries to enable set() and intersection() methods\n",
    "\n",
    "eval_truth = []\n",
    "for m in evaluated.iterrows():\n",
    "    eval_truth.append(f'{m[1][2]} {m[1][0]} {m[1][1]} {m[1][3]}')\n",
    "\n",
    "eval_test = []\n",
    "for n in evaluated2.iterrows():\n",
    "    eval_test.append(f'{n[1][3]} {n[1][0]} {n[1][1]} {n[1][4]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 117 \n",
      "FP: 15 \n",
      "FN: 33\n",
      "PRECISION: 88.63636363636364 \n",
      "RECALL: 78.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance (rudimentary?)\n",
    "\n",
    "tp = len(set(eval_test).intersection(eval_truth)) # correct labels\n",
    "fp = len(set(eval_test)) - len(set(eval_test).intersection(eval_truth)) # things that were labeled that shouldn't have been\n",
    "\n",
    "fn = len(eval_truth) - (len(set(eval_test).intersection(eval_truth))) # things that should've been labeled but were not\n",
    "\n",
    "precision = (tp/(tp+fp))*100\n",
    "recall = (tp/(tp+fn))*100\n",
    "\n",
    "\n",
    "print(f'TP: {tp} \\nFP: {fp} \\nFN: {fn}')\n",
    "print(f'PRECISION: {precision} \\nRECALL: {recall}')\n",
    "# print(f'F1: {(2*(precision*recall))/(precision+recall)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>24</td>\n",
       "      <td>Zenchent Fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>37</td>\n",
       "      <td>norethindrone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>55</td>\n",
       "      <td>ethinyl estradiol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>95</td>\n",
       "      <td>ferrous fumarate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>203</td>\n",
       "      <td>Zenchent Fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>46</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>36</td>\n",
       "      <td>prilocaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>100</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>91</td>\n",
       "      <td>lidocaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>120</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>110</td>\n",
       "      <td>prilocaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>333</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>324</td>\n",
       "      <td>Lidocaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>348</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>338</td>\n",
       "      <td>prilocaine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     end    entity start               word\n",
       "0     35  CHEMICAL    24        Zenchent Fe\n",
       "1     50  CHEMICAL    37      norethindrone\n",
       "2     72  CHEMICAL    55  ethinyl estradiol\n",
       "3    111  CHEMICAL    95   ferrous fumarate\n",
       "4    214  CHEMICAL   203        Zenchent Fe\n",
       "..   ...       ...   ...                ...\n",
       "145   46  CHEMICAL    36         prilocaine\n",
       "146  100  CHEMICAL    91          lidocaine\n",
       "147  120  CHEMICAL   110         prilocaine\n",
       "148  333  CHEMICAL   324          Lidocaine\n",
       "149  348  CHEMICAL   338         prilocaine\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluated # TRUTH SET / HUMAN LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>24</td>\n",
       "      <td>Memantine hydrochloride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>54</td>\n",
       "      <td>N - methyl - D - aspartate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>192</td>\n",
       "      <td>Memantine hydrochloride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>37</td>\n",
       "      <td>norethindrone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>55</td>\n",
       "      <td>ethinyl estradiol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>46</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>36</td>\n",
       "      <td>prilocaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>100</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>91</td>\n",
       "      <td>lidocaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>120</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>110</td>\n",
       "      <td>prilocaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>333</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>324</td>\n",
       "      <td>Lidocaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>348</td>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>338</td>\n",
       "      <td>prilocaine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     end entity_group     score  start                        word\n",
       "0     47     CHEMICAL  0.999998     24     Memantine hydrochloride\n",
       "1     74     CHEMICAL  0.999998     54  N - methyl - D - aspartate\n",
       "2    215     CHEMICAL  0.999998    192     Memantine hydrochloride\n",
       "3     50     CHEMICAL  0.999998     37               norethindrone\n",
       "4     72     CHEMICAL  0.999996     55           ethinyl estradiol\n",
       "..   ...          ...       ...    ...                         ...\n",
       "127   46     CHEMICAL  0.999998     36                  prilocaine\n",
       "128  100     CHEMICAL  0.999998     91                   lidocaine\n",
       "129  120     CHEMICAL  0.999998    110                  prilocaine\n",
       "130  333     CHEMICAL  0.999998    324                   Lidocaine\n",
       "131  348     CHEMICAL  0.999998    338                  prilocaine\n",
       "\n",
       "[132 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluated2 # MODEL PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    132.000000\n",
       "mean       0.995811\n",
       "std        0.033766\n",
       "min        0.638223\n",
       "25%        0.999987\n",
       "50%        0.999997\n",
       "75%        0.999998\n",
       "max        0.999999\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluated2['score'].describe() # TODO: is there a setting that automatically sets a threshold, i.e. why the observed predictions are always 0.5 or 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seqeval WIP\n",
    "I want to use the evaluate.load(\"seqeval\") method demonstrated in the huggingface tutorial, but I am at a loss for how to maintain label positions from the human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'human', 'bert'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "\n",
    "for entry in dataset['text'][0:3]:\n",
    "    for string in entry:\n",
    "        tags = [\"0\"] * len(string)\n",
    "        print(tags)\n",
    "\n",
    "        # for character in string:\n",
    "            # print(character)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': '35', 'entity': 'CHEMICAL', 'start': '24', 'word': 'Zenchent Fe'},\n",
       " {'end': '50', 'entity': 'CHEMICAL', 'start': '37', 'word': 'norethindrone'},\n",
       " {'end': '72',\n",
       "  'entity': 'CHEMICAL',\n",
       "  'start': '55',\n",
       "  'word': 'ethinyl estradiol'},\n",
       " {'end': '111',\n",
       "  'entity': 'CHEMICAL',\n",
       "  'start': '95',\n",
       "  'word': 'ferrous fumarate'},\n",
       " {'end': '214', 'entity': 'CHEMICAL', 'start': '203', 'word': 'Zenchent Fe'},\n",
       " {'end': '229', 'entity': 'CHEMICAL', 'start': '216', 'word': 'norethindrone'},\n",
       " {'end': '251',\n",
       "  'entity': 'CHEMICAL',\n",
       "  'start': '234',\n",
       "  'word': 'ethinyl estradiol'},\n",
       " {'end': '290',\n",
       "  'entity': 'CHEMICAL',\n",
       "  'start': '274',\n",
       "  'word': 'ferrous fumarate'},\n",
       " {'end': '313', 'entity': 'CHEMICAL', 'start': '304', 'word': 'progestin'},\n",
       " {'end': '322', 'entity': 'CHEMICAL', 'start': '314', 'word': 'estrogen'}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['human'][1]\n",
    "# dataset['text'][1][0][24:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " '0',\n",
       " '0',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " '0',\n",
       " '0',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " '0',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL',\n",
       " 'CHEMICAL']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['human'][1]\n",
    "\n",
    "tags = [\"0\"] * len(dataset['text'][0][0])\n",
    "print(tags)\n",
    "\n",
    "for entity in dataset['human'][1]:\n",
    "    start = int(entity['start'])\n",
    "    end = int(entity['end'])\n",
    "    label = entity['entity']\n",
    "    tags[start:end] = [label] * (end-start)\n",
    "\n",
    "tags[start:end]\n",
    "tags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectname",
   "language": "python",
   "name": "projectname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5665ddc6d7544238f2e637974fb7ce0cd2b3fcbe310ce6232a6d3529e702b4ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
